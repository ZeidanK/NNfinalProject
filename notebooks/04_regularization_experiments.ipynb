{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bf8821",
   "metadata": {},
   "source": [
    "# Notebook 04: Regularization Experiments\n",
    "\n",
    "**Objective**: Systematically test regularization techniques (Dropout, L2, Batch Normalization) to reduce overfitting and improve generalization.\n",
    "\n",
    "**Base Architecture**: [128, 64, 32] (selected from Notebook 03 as a balanced medium-depth network)\n",
    "\n",
    "**Experiments**:\n",
    "1. **Dropout**: Test rates [0.0, 0.2, 0.3, 0.4, 0.5]\n",
    "2. **L2 Regularization**: Test strengths [0.0, 0.001, 0.01, 0.1]\n",
    "3. **Batch Normalization**: With and without\n",
    "4. **Combined**: Best dropout + best L2 + batch norm\n",
    "\n",
    "**Evaluation**: Compare validation loss trajectories and PR-AUC to identify optimal regularization strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import config\n",
    "from src.nn_architectures import create_mlp\n",
    "from src.nn_training_utils import train_neural_network, get_class_weights\n",
    "from src.evaluation_metrics import compute_fraud_metrics\n",
    "from src.visualization_utils import plot_learning_curves\n",
    "\n",
    "# Set random seeds\n",
    "config.set_random_seeds()\n",
    "\n",
    "print(\"âœ“ Imports complete\")\n",
    "print(f\"âœ“ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ“ Random seed set to {config.RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f95be",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "df = pd.read_csv(config.DATASET_PATH)\n",
    "X = df[config.FEATURE_COLUMNS].values\n",
    "y = df[config.TARGET_COLUMN].values\n",
    "\n",
    "# Load saved split indices\n",
    "train_idx = np.load(config.TRAIN_INDICES_PATH)\n",
    "val_idx = np.load(config.VAL_INDICES_PATH)\n",
    "test_idx = np.load(config.TEST_INDICES_PATH)\n",
    "\n",
    "# Split data\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_val, y_val = X[val_idx], y[val_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "# Load and apply scaler\n",
    "scaler = joblib.load(config.FITTED_SCALER_PATH)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = get_class_weights(y_train)\n",
    "\n",
    "print(\"âœ“ Data loaded and preprocessed\")\n",
    "print(f\"  Train: {X_train_scaled.shape[0]:,} samples\")\n",
    "print(f\"  Val:   {X_val_scaled.shape[0]:,} samples\")\n",
    "print(f\"  Test:  {X_test_scaled.shape[0]:,} samples\")\n",
    "print(f\"âœ“ Class weights: {{0: {class_weights[0]:.4f}, 1: {class_weights[1]:.4f}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce42d6b",
   "metadata": {},
   "source": [
    "## 2. Experiment 1: Dropout Regularization\n",
    "\n",
    "Test dropout rates from 0.0 to 0.5 on base architecture [128, 64, 32]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2046324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout experiments\n",
    "base_architecture = [128, 64, 32]\n",
    "dropout_rates = [0.0, 0.2, 0.3, 0.4, 0.5]\n",
    "dropout_results = []\n",
    "dropout_histories = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 1: DROPOUT REGULARIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for dropout in dropout_rates:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with Dropout = {dropout}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create model with dropout\n",
    "    model = create_mlp(\n",
    "        input_dim=X_train_scaled.shape[1],\n",
    "        hidden_layers=base_architecture,\n",
    "        dropout_rate=dropout,\n",
    "        l2_reg=0.0,\n",
    "        use_batch_norm=False\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history, trained_model, train_time = train_neural_network(\n",
    "        model=model,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_scaled,\n",
    "        y_val=y_val,\n",
    "        class_weights=class_weights,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        patience=15,\n",
    "        experiment_name=f\"dropout_{dropout}\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_val_pred_proba = trained_model.predict(X_val_scaled, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
    "    metrics = compute_fraud_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
    "    \n",
    "    dropout_results.append({\n",
    "        'dropout': dropout,\n",
    "        'pr_auc': metrics['pr_auc'],\n",
    "        'roc_auc': metrics['roc_auc'],\n",
    "        'f1_fraud': metrics['fraud_f1'],\n",
    "        'val_loss': min(history.history['val_loss']),\n",
    "        'epochs': len(history.history['loss'])\n",
    "    })\n",
    "    \n",
    "    dropout_histories[dropout] = history\n",
    "    \n",
    "    print(f\"âœ“ PR-AUC: {metrics['pr_auc']:.4f} | Val Loss: {dropout_results[-1]['val_loss']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ Dropout experiments complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762be012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Dropout comparison\n",
    "ax1 = axes[0, 0]\n",
    "dropout_df_plot = dropout_df.sort_values('dropout')\n",
    "ax1.plot(dropout_df_plot['dropout'], dropout_df_plot['pr_auc'], marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "ax1.set_xlabel('Dropout Rate', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('PR-AUC (Validation)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Dropout Regularization Effect', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(best_dropout, color='red', linestyle='--', linewidth=2, label=f'Best: {best_dropout}')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. L2 comparison\n",
    "ax2 = axes[0, 1]\n",
    "l2_df_plot = l2_df.sort_values('l2_reg')\n",
    "ax2.semilogx(l2_df_plot['l2_reg'][1:], l2_df_plot['pr_auc'][1:], marker='o', linewidth=2, markersize=8, color='coral')\n",
    "ax2.scatter([l2_df_plot.iloc[0]['l2_reg']], [l2_df_plot.iloc[0]['pr_auc']], s=100, color='coral', marker='o', zorder=5)\n",
    "ax2.set_xlabel('L2 Regularization Strength', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('PR-AUC (Validation)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('L2 Regularization Effect', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(best_l2 if best_l2 > 0 else 0.0001, color='red', linestyle='--', linewidth=2, label=f'Best: {best_l2}')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Batch Normalization comparison\n",
    "ax3 = axes[1, 0]\n",
    "bn_df_plot = bn_df\n",
    "colors = ['#e74c3c' if row['batch_norm'] == 'Yes' and best_bn else '#3498db' if row['batch_norm'] == 'No' and not best_bn else '#95a5a6' for _, row in bn_df_plot.iterrows()]\n",
    "bars = ax3.bar(range(len(bn_df_plot)), bn_df_plot['pr_auc'], color=colors, edgecolor='black', linewidth=2)\n",
    "ax3.set_xticks(range(len(bn_df_plot)))\n",
    "ax3.set_xticklabels(bn_df_plot['batch_norm'])\n",
    "ax3.set_xlabel('Batch Normalization', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('PR-AUC (Validation)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Batch Normalization Effect', fontsize=13, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. All techniques comparison\n",
    "ax4 = axes[1, 1]\n",
    "all_results = {\n",
    "    'Baseline\\\\n(no reg)': dropout_df[dropout_df['dropout'] == 0.0]['pr_auc'].values[0],\n",
    "    f'Best Dropout\\\\n({best_dropout})': dropout_df[dropout_df['dropout'] == best_dropout]['pr_auc'].values[0],\n",
    "    f'Best L2\\\\n({best_l2})': l2_df[l2_df['l2_reg'] == best_l2]['pr_auc'].values[0],\n",
    "    f'Best BN\\\\n({\\\"Yes\\\" if best_bn else \\\"No\\\"})': bn_df[bn_df['batch_norm'] == ('Yes' if best_bn else 'No')]['pr_auc'].values[0],\n",
    "    'Combined': metrics_combined['pr_auc']\n",
    "}\n",
    "bars = ax4.bar(range(len(all_results)), list(all_results.values()), color='purple', alpha=0.7, edgecolor='black', linewidth=2)\n",
    "bars[-1].set_color('#2ecc71')  # Highlight combined\n",
    "ax4.set_xticks(range(len(all_results)))\n",
    "ax4.set_xticklabels(list(all_results.keys()), rotation=0, fontsize=10)\n",
    "ax4.set_ylabel('PR-AUC (Validation)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Regularization Techniques Comparison', fontsize=13, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, (label, value) in enumerate(all_results.items()):\n",
    "    ax4.text(i, value + 0.005, f'{value:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Regularization Experiments - Fraud Detection Neural Network', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/regularization_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save all results\n",
    "all_reg_results = pd.concat([\n",
    "    dropout_df.assign(experiment='dropout'),\n",
    "    l2_df.assign(experiment='l2'),\n",
    "    bn_df.assign(experiment='batch_norm')\n",
    "], ignore_index=True)\n",
    "\n",
    "os.makedirs('../results/tables', exist_ok=True)\n",
    "all_reg_results.to_csv('../results/tables/regularization_experiments.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" NOTEBOOK 04 SUMMARY - REGULARIZATION EXPERIMENTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ“ Dropout experiments: {len(dropout_rates)} configurations tested\")\n",
    "print(f\"âœ“ L2 experiments: {len(l2_strengths)} configurations tested\")\n",
    "print(f\"âœ“ Batch Norm experiments: 2 configurations tested\")\n",
    "print(f\"\\nðŸ† Best Hyperparameters:\")\n",
    "print(f\"  Dropout: {best_dropout}\")\n",
    "print(f\"  L2: {best_l2}\")\n",
    "print(f\"  Batch Normalization: {'Yes' if best_bn else 'No'}\")\n",
    "print(f\"\\nðŸ“Š Performance:\")\n",
    "print(f\"  Baseline (no reg): {all_results['Baseline\\\\n(no reg)']:.4f}\")\n",
    "print(f\"  Combined optimal: {metrics_combined['pr_auc']:.4f}\")\n",
    "print(f\"  Improvement: +{(metrics_combined['pr_auc'] - all_results['Baseline\\\\n(no reg)']) / all_results['Baseline\\\\n(no reg)'] * 100:.2f}%\")\n",
    "print(\"\\nâœ… Notebook 04 Complete!\")\n",
    "print(\"ðŸš€ Ready for Notebook 05: Class Imbalance Strategies\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02900f",
   "metadata": {},
   "source": [
    "## 6. Visualization & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dba719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best hyperparameters from each experiment\n",
    "dropout_df = pd.DataFrame(dropout_results)\n",
    "l2_df = pd.DataFrame(l2_results)\n",
    "bn_df = pd.DataFrame(bn_results)\n",
    "\n",
    "best_dropout = dropout_df.loc[dropout_df['pr_auc'].idxmax(), 'dropout']\n",
    "best_l2 = l2_df.loc[l2_df['pr_auc'].idxmax(), 'l2_reg']\n",
    "best_bn = bn_df.loc[bn_df['pr_auc'].idxmax(), 'batch_norm'] == 'Yes'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"OPTIMAL HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best Dropout: {best_dropout}\")\n",
    "print(f\"Best L2: {best_l2}\")\n",
    "print(f\"Best Batch Norm: {'Yes' if best_bn else 'No'}\")\n",
    "\n",
    "# Train combined model\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Training COMBINED model with optimal settings\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "model_combined = create_mlp(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    hidden_layers=base_architecture,\n",
    "    dropout_rate=best_dropout,\n",
    "    l2_reg=best_l2,\n",
    "    use_batch_norm=best_bn\n",
    ")\n",
    "\n",
    "history_combined, model_combined_trained, _ = train_neural_network(\n",
    "    model=model_combined,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_scaled,\n",
    "    y_val=y_val,\n",
    "    class_weights=class_weights,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    patience=15,\n",
    "    experiment_name=\"combined_regularization\"\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred_proba = model_combined_trained.predict(X_val_scaled, verbose=0).flatten()\n",
    "y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
    "metrics_combined = compute_fraud_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
    "\n",
    "print(f\"\\nâœ“ Combined model PR-AUC: {metrics_combined['pr_auc']:.4f}\")\n",
    "print(f\"âœ“ Combined model saved to: ../models/combined_regularization.keras\")\n",
    "model_combined_trained.save('../models/combined_regularization.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098a9cb",
   "metadata": {},
   "source": [
    "## 5. Combined Regularization\n",
    "\n",
    "Train model with optimal combination of regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da98efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization experiments\n",
    "bn_configs = [False, True]\n",
    "bn_results = []\n",
    "bn_histories = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 3: BATCH NORMALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for use_bn in bn_configs:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training {'WITH' if use_bn else 'WITHOUT'} Batch Normalization\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_mlp(\n",
    "        input_dim=X_train_scaled.shape[1],\n",
    "        hidden_layers=base_architecture,\n",
    "        dropout_rate=0.0,\n",
    "        l2_reg=0.0,\n",
    "        use_batch_norm=use_bn\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history, trained_model, train_time = train_neural_network(\n",
    "        model=model,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_scaled,\n",
    "        y_val=y_val,\n",
    "        class_weights=class_weights,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        patience=15,\n",
    "        experiment_name=f\"batchnorm_{use_bn}\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_val_pred_proba = trained_model.predict(X_val_scaled, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
    "    metrics = compute_fraud_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
    "    \n",
    "    bn_results.append({\n",
    "        'batch_norm': 'Yes' if use_bn else 'No',\n",
    "        'pr_auc': metrics['pr_auc'],\n",
    "        'roc_auc': metrics['roc_auc'],\n",
    "        'f1_fraud': metrics['fraud_f1'],\n",
    "        'val_loss': min(history.history['val_loss']),\n",
    "        'epochs': len(history.history['loss'])\n",
    "    })\n",
    "    \n",
    "    bn_histories[use_bn] = history\n",
    "    \n",
    "    print(f\"âœ“ PR-AUC: {metrics['pr_auc']:.4f} | Val Loss: {bn_results[-1]['val_loss']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ Batch Normalization experiments complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6c29a",
   "metadata": {},
   "source": [
    "## 4. Experiment 3: Batch Normalization\n",
    "\n",
    "Compare performance with and without Batch Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization experiments\n",
    "l2_strengths = [0.0, 0.001, 0.01, 0.1]\n",
    "l2_results = []\n",
    "l2_histories = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 2: L2 REGULARIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for l2_reg in l2_strengths:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with L2 = {l2_reg}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create model with L2\n",
    "    model = create_mlp(\n",
    "        input_dim=X_train_scaled.shape[1],\n",
    "        hidden_layers=base_architecture,\n",
    "        dropout_rate=0.0,\n",
    "        l2_reg=l2_reg,\n",
    "        use_batch_norm=False\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history, trained_model, train_time = train_neural_network(\n",
    "        model=model,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_scaled,\n",
    "        y_val=y_val,\n",
    "        class_weights=class_weights,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        patience=15,\n",
    "        experiment_name=f\"l2_{l2_reg}\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_val_pred_proba = trained_model.predict(X_val_scaled, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
    "    metrics = compute_fraud_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
    "    \n",
    "    l2_results.append({\n",
    "        'l2_reg': l2_reg,\n",
    "        'pr_auc': metrics['pr_auc'],\n",
    "        'roc_auc': metrics['roc_auc'],\n",
    "        'f1_fraud': metrics['fraud_f1'],\n",
    "        'val_loss': min(history.history['val_loss']),\n",
    "        'epochs': len(history.history['loss'])\n",
    "    })\n",
    "    \n",
    "    l2_histories[l2_reg] = history\n",
    "    \n",
    "    print(f\"âœ“ PR-AUC: {metrics['pr_auc']:.4f} | Val Loss: {l2_results[-1]['val_loss']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ L2 experiments complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fb8b9",
   "metadata": {},
   "source": [
    "## 3. Experiment 2: L2 Regularization\n",
    "\n",
    "Test L2 penalty strengths from 0.0 to 0.1 on base architecture."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
