{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d903852b",
   "metadata": {},
   "source": [
    "# Notebook 02: Preprocessing & Baseline Comparison\n",
    "\n",
    "**Objective**: Establish the preprocessing pipeline and baseline model performance for later comparison with neural networks.\n",
    "\n",
    "**Critical for Reproducibility**: This notebook creates the **train/validation/test splits** and **fitted StandardScaler** that will be reused by all subsequent notebooks. These artifacts are saved to disk to prevent data leakage.\n",
    "\n",
    "**Contents**:\n",
    "1. Load and split data (70% train / 15% validation / 15% test, stratified)\n",
    "2. Fit StandardScaler on training data only\n",
    "3. Train and evaluate baseline models (Logistic Regression, Random Forest)\n",
    "4. Save splits, scaler, and baseline performance for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import config\n",
    "from src.evaluation_metrics import compute_fraud_metrics, print_classification_summary\n",
    "from src.visualization_utils import plot_confusion_matrix, plot_precision_recall_curve\n",
    "\n",
    "# Set random seeds\n",
    "config.set_random_seeds()\n",
    "\n",
    "# Ensure directories\n",
    "config.ensure_directories()\n",
    "\n",
    "print(\"‚úì Imports complete\")\n",
    "print(f\"‚úì Random seed set to {config.RANDOM_SEED}\")\n",
    "print(f\"‚úì Results will be saved to: {config.RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606dbb6",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(config.DATA_PATH)\n",
    "print(f\"‚úì Loaded {df.shape[0]:,} transactions with {df.shape[1]} features\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df[config.FEATURE_COLUMNS].values\n",
    "y = df[config.TARGET_COLUMN].values\n",
    "\n",
    "print(f\"\\n‚úì Features shape: {X.shape}\")\n",
    "print(f\"‚úì Target shape: {y.shape}\")\n",
    "print(f\"‚úì Fraud prevalence: {y.mean()*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e2926",
   "metadata": {},
   "source": [
    "## 2. Create Stratified Train/Validation/Test Splits\n",
    "\n",
    "**Critical Decision**: We use a 70/15/15 split with stratification to maintain class balance across sets. Split indices are **saved** to ensure all subsequent notebooks use identical data partitions (prevents leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 70% train, 30% temp (for val+test)\n",
    "X_train, X_temp, y_train, y_temp, train_idx, temp_idx = train_test_split(\n",
    "    X, y, np.arange(len(y)),\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Second split: 50% of temp (15% of total) for validation, 50% for test\n",
    "X_val, X_test, y_val, y_test, val_idx_temp, test_idx_temp = train_test_split(\n",
    "    X_temp, y_temp, np.arange(len(y_temp)),\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Map temp indices back to original indices\n",
    "val_idx = temp_idx[val_idx_temp]\n",
    "test_idx = temp_idx[test_idx_temp]\n",
    "\n",
    "# Save indices for reproducibility\n",
    "np.save(config.TRAIN_INDICES_PATH, train_idx)\n",
    "np.save(config.VAL_INDICES_PATH, val_idx)\n",
    "np.save(config.TEST_INDICES_PATH, test_idx)\n",
    "\n",
    "print(\"‚úì Data split complete:\")\n",
    "print(f\"  Train: {len(train_idx):,} samples ({len(train_idx)/len(y)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_idx):,} samples ({len(val_idx)/len(y)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_idx):,} samples ({len(test_idx)/len(y)*100:.1f}%)\")\n",
    "print(f\"\\n‚úì Class distribution:\")\n",
    "print(f\"  Train fraud rate: {y_train.mean()*100:.4f}%\")\n",
    "print(f\"  Val fraud rate:   {y_val.mean()*100:.4f}%\")\n",
    "print(f\"  Test fraud rate:  {y_test.mean()*100:.4f}%\")\n",
    "print(f\"\\n‚úì Split indices saved to:\")\n",
    "print(f\"  {config.TRAIN_INDICES_PATH}\")\n",
    "print(f\"  {config.VAL_INDICES_PATH}\")\n",
    "print(f\"  {config.TEST_INDICES_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c7f99",
   "metadata": {},
   "source": [
    "## 3. Fit StandardScaler on Training Data\n",
    "\n",
    "**Critical for Data Leakage Prevention**: The scaler is fit **only** on training data, then applied to validation and test sets. The fitted scaler is saved for use in all subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit scaler on training data ONLY\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform validation and test using fitted scaler\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save fitted scaler\n",
    "joblib.dump(scaler, config.SCALER_PATH)\n",
    "\n",
    "print(\"‚úì StandardScaler fitted on training data\")\n",
    "print(f\"‚úì Scaler saved to: {config.SCALER_PATH}\")\n",
    "print(f\"\\n‚úì Feature statistics (from training data):\")\n",
    "print(f\"  Mean range: [{scaler.mean_.min():.4f}, {scaler.mean_.max():.4f}]\")\n",
    "print(f\"  Std range:  [{scaler.scale_.min():.4f}, {scaler.scale_.max():.4f}]\")\n",
    "print(f\"\\n‚úì Scaled data statistics:\")\n",
    "print(f\"  Train - Mean: {X_train_scaled.mean():.6f}, Std: {X_train_scaled.std():.6f}\")\n",
    "print(f\"  Val   - Mean: {X_val_scaled.mean():.6f}, Std: {X_val_scaled.std():.6f}\")\n",
    "print(f\"  Test  - Mean: {X_test_scaled.mean():.6f}, Std: {X_test_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93245f",
   "metadata": {},
   "source": [
    "## 4. Baseline Model 1: Logistic Regression\n",
    "\n",
    "We train a simple Logistic Regression with `class_weight='balanced'` to handle class imbalance. This provides a linear baseline for comparison with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression with balanced class weights...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=config.RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Predictions on validation set\n",
    "y_val_pred_proba_lr = lr_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_val_pred_lr = lr_model.predict(X_val_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "lr_metrics = compute_fraud_metrics(y_val, y_val_pred_lr, y_val_pred_proba_lr)\n",
    "\n",
    "print(f\"\\n‚úì Training complete in {train_time:.2f} seconds\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOGISTIC REGRESSION - Validation Performance\")\n",
    "print(\"=\"*60)\n",
    "print_classification_summary(lr_metrics)\n",
    "\n",
    "# Save model\n",
    "lr_model_path = os.path.join(config.MODELS_DIR, 'logistic_regression_baseline.pkl')\n",
    "joblib.dump(lr_model, lr_model_path)\n",
    "print(f\"\\n‚úì Model saved to: {lr_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd29f5bd",
   "metadata": {},
   "source": [
    "## 5. Baseline Model 2: Random Forest\n",
    "\n",
    "Random Forest provides a non-linear baseline with ensemble learning. We use `class_weight='balanced'` and limit tree depth to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b81efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest with balanced class weights...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    random_state=config.RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Predictions on validation set\n",
    "y_val_pred_proba_rf = rf_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_val_pred_rf = rf_model.predict(X_val_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "rf_metrics = compute_fraud_metrics(y_val, y_val_pred_rf, y_val_pred_proba_rf)\n",
    "\n",
    "print(f\"\\n‚úì Training complete in {train_time:.2f} seconds\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM FOREST - Validation Performance\")\n",
    "print(\"=\"*60)\n",
    "print_classification_summary(rf_metrics)\n",
    "\n",
    "# Save model\n",
    "rf_model_path = os.path.join(config.MODELS_DIR, 'random_forest_baseline.pkl')\n",
    "joblib.dump(rf_model, rf_model_path)\n",
    "print(f\"\\n‚úì Model saved to: {rf_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40116a4",
   "metadata": {},
   "source": [
    "## 6. Visualize Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize baseline comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Confusion matrices\n",
    "plot_confusion_matrix(y_val, y_val_pred_lr, ['Legitimate', 'Fraud'], \n",
    "                     title='Logistic Regression - Confusion Matrix', ax=axes[0, 0])\n",
    "plot_confusion_matrix(y_val, y_val_pred_rf, ['Legitimate', 'Fraud'],\n",
    "                     title='Random Forest - Confusion Matrix', ax=axes[0, 1])\n",
    "\n",
    "# PR curves\n",
    "plot_precision_recall_curve(y_val, y_val_pred_proba_lr, \n",
    "                            title='Logistic Regression - PR Curve', ax=axes[1, 0])\n",
    "plot_precision_recall_curve(y_val, y_val_pred_proba_rf,\n",
    "                            title='Random Forest - PR Curve', ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/baseline_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved: baseline_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b28cc",
   "metadata": {},
   "source": [
    "## 7. Save Baseline Performance Targets\n",
    "\n",
    "These baseline metrics will be used to compare neural network performance in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline summary DataFrame\n",
    "baseline_results = pd.DataFrame({\n",
    "    'model': ['Logistic Regression', 'Random Forest'],\n",
    "    'pr_auc': [lr_metrics['pr_auc'], rf_metrics['pr_auc']],\n",
    "    'roc_auc': [lr_metrics['roc_auc'], rf_metrics['roc_auc']],\n",
    "    'f1_fraud': [lr_metrics['fraud_f1'], rf_metrics['fraud_f1']],\n",
    "    'precision_fraud': [lr_metrics['fraud_precision'], rf_metrics['fraud_precision']],\n",
    "    'recall_fraud': [lr_metrics['fraud_recall'], rf_metrics['fraud_recall']],\n",
    "    'accuracy': [lr_metrics['accuracy'], rf_metrics['accuracy']]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "baseline_path = os.path.join(config.RESULTS_DIR, 'tables', 'baseline_performance_targets.csv')\n",
    "baseline_results.to_csv(baseline_path, index=False)\n",
    "\n",
    "print(\"‚úì Baseline performance summary:\")\n",
    "print(baseline_results.to_string(index=False))\n",
    "print(f\"\\n‚úì Saved to: {baseline_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3445023",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" NOTEBOOK 02 SUMMARY - PREPROCESSING & BASELINES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úì Data split: {len(train_idx):,} train / {len(val_idx):,} val / {len(test_idx):,} test\")\n",
    "print(f\"‚úì Scaler fitted and saved: {config.SCALER_PATH}\")\n",
    "print(f\"‚úì Split indices saved for reproducibility\")\n",
    "print(\"\\nüìä Baseline Performance (Validation Set):\")\n",
    "print(f\"  Logistic Regression:\")\n",
    "print(f\"    - PR-AUC: {lr_metrics['pr_auc']:.4f}\")\n",
    "print(f\"    - ROC-AUC: {lr_metrics['roc_auc']:.4f}\")\n",
    "print(f\"    - F1 (Fraud): {lr_metrics['fraud_f1']:.4f}\")\n",
    "print(f\"  Random Forest:\")\n",
    "print(f\"    - PR-AUC: {rf_metrics['pr_auc']:.4f}\")\n",
    "print(f\"    - ROC-AUC: {rf_metrics['roc_auc']:.4f}\")\n",
    "print(f\"    - F1 (Fraud): {rf_metrics['fraud_f1']:.4f}\")\n",
    "\n",
    "print(\"\\nüéØ Performance Targets for Neural Networks:\")\n",
    "print(f\"  - Must exceed: PR-AUC > {max(lr_metrics['pr_auc'], rf_metrics['pr_auc']):.4f}\")\n",
    "print(f\"  - Goal: PR-AUC > 0.80 (significant improvement over baselines)\")\n",
    "\n",
    "print(\"\\nüìÅ Artifacts Created:\")\n",
    "artifacts = [\n",
    "    config.TRAIN_INDICES_PATH,\n",
    "    config.VAL_INDICES_PATH,\n",
    "    config.TEST_INDICES_PATH,\n",
    "    config.SCALER_PATH,\n",
    "    baseline_path,\n",
    "    '../results/figures/baseline_comparison.png'\n",
    "]\n",
    "for artifact in artifacts:\n",
    "    print(f\"   {artifact}\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook 02 Complete!\")\n",
    "print(\"üöÄ Ready for Notebook 03: Neural Network Architecture Exploration\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
